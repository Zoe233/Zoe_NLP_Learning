一、K-means聚类算法
1.1、K-means 算法思想、算法描述
K——指我们最后聚成的有K个类；means——平均，指我们在做聚类时选用类间平均距离进行计算
K-means 的算法思想：是通过迭代过程把数据集划分为不同的类别，使得评价聚类性能的准则函数达到最优，从而使生成的每个类做到——类内紧凑，类间独立。
K-means 的算法描述如下图：

算法描述：
1. 为中心向量c1，c2,...ck初始化k个种子
2. 分组：
    将样本分配给距离（平均距离）其最近的中心向量
3.确定中心：
    用各个聚类的中心向量作为新的中心
4.重复分组和确定中心的步骤，直至算法收敛。



1.3、举实例使用K-means算法进行聚类
举个栗子：我们有五个样本点a(0,2)、b(0,0)、c(1.5,0)、d(5,0)、e(5,2)，选取前两个样本点a(0,2)、b(0,0)作为初始聚类中心点A、B，开始聚类：

a. 对于点c(1.5,0)，到a点的（欧式）距离为2.5，到b点距离为1.5，所以c点分配给B类；
b. 同例，d点分入B类、e点分入A类；于是更新后得到的新簇：A类={a,e},B类={b,c,d}
c. 每迭代一次都计算一次平均误差：平均误差是等于新簇内的点到原有中心点距离的平方和，例如：
        E_{A} = d(a,a)+d(a,e) = [(0-0)^2+(2-2)^2]+[(0-5)^2+(2-2)^2] =25
        E_{B} = 27.25
    再得到总体的平均误差E = 25+27.25 = 52.25
d. 重新计算新的簇内中心点：
    A=((0+5)/2,(2+2)/2)=(2.5,2)、
    B=((0+1.5+5)/3,(0+0+0)/3)=(2.17,0)，
   重复1、2、3步骤，再得到新的平均误差E=25.62，误差显著减小。
   由于经过两次迭代后，中心点不再变化，所以停止迭代，聚类结束。

1.4、K-means 算法优缺点
优点：如果样本集是团簇密集状的，K-means聚类方法效果较好
缺点：
    对于条状、环形状等非团簇状的样本集，聚类效果一般；
    对于事先给定的K值、初始点敏感，不同K值、初始点可能导致聚类得到结果差异较大；
    也可能因为初始点分属同一类，导致最后结果陷入局部最小值，无法达到全局最优解。


1.5、K值的选取原则——肘部法则
由于K-means 算法对初选的K值是敏感的，计算平均误差就是为了K值的选取，请看下图：

平均误差会随K值的选取而改变，随着K值增大，平均误差会逐渐降低；
极限情况下是每个样本点是都是一个类，这时的平均误差E=0，当然这种聚类没有研究的价值。

那么哪个K值是最佳选取的值呢——肘部法则，
    就是选取斜率变化较大的拐点处定为K值点，这只是一种简单的选取规则，方便简单而且实用。