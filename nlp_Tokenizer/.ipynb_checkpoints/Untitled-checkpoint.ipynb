{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jieba分词器的介绍和整理\n",
    "# 1.三种分词模式和一个参数\n",
    "#     精确模式 - 视图把句子最精确地切开，适合文本分析\n",
    "#     全模式 - 把句子中所有的可以成词的词语都扫描出来，速度非常快，但不你解决歧义\n",
    "#     搜索引擎模式 - 在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词\n",
    "# 2.支持自定义词典\n",
    "# 3.中文歧义测试和去除停用词\n",
    "# 4.三种可以让分词更准确的方法\n",
    "# 5.并行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 算法：\n",
    "#     基于词缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图（DAG）；\n",
    "#     采用了动态规划查找最大概率路径，找到基于词频的最大切分组合；\n",
    "#     对于未登录词，采用了基于汉字成词能力的HMM模型，使用了Viterbi算法。\n",
    "# 注：未登录词即没有被收录在分词词表中但必须切分出来的词，\n",
    "# 包括各类专有名词（人名、地名、企业名等）、缩写词、新增词汇等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jieba.cut的默认参数只有三个\n",
    "# jieba(self, sentence, cut_all= False, HMM = True)\n",
    "# 参数：sentence 输入文本\n",
    "#      cut_all 是否为全模式分词\n",
    "#      HMM 是否开启HMM进行中文分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jieba.cut 方法接受三个输入参数: \n",
    "#         需要分词的字符串；\n",
    "#         cut_all 参数用来控制是否采用全模式；\n",
    "#         HMM 参数用来控制是否使用 HMM 模型\n",
    "\n",
    "# jieba.cut_for_search 方法接受两个参数：\n",
    "#         需要分词的字符串；\n",
    "#         是否使用 HMM 模型。\n",
    "#         该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细\n",
    "\n",
    "# 待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。\n",
    "# 注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8\n",
    "\n",
    "# jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，\n",
    "#     可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用\n",
    "# jieba.lcut 以及 jieba.lcut_for_search 直接返回 list\n",
    "\n",
    "# jieba.Tokenizer(dictionary=DEFAULT_DICT) \n",
    "#     新建自定义分词器，可用于同时使用不同词典。\n",
    "#     jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n",
      "他, 来到, 了, 网易, 杭研, 大厦\n",
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method cut in module jieba:\n",
      "\n",
      "cut(sentence, cut_all=False, HMM=True) method of jieba.Tokenizer instance\n",
      "    The main function that segments an entire sentence that contains\n",
      "    Chinese characters into seperated words.\n",
      "    \n",
      "    Parameter:\n",
      "        - sentence: The str(unicode) to be segmented.\n",
      "        - cut_all: Model type. True for full pattern, False for accurate pattern.\n",
      "        - HMM: Whether to use the Hidden Markov Model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(jieba.cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. 添加自定义词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 载入词典\n",
    "# 开发者可以指定自己自定义的词典，以便包含 jieba 词库里没有的词。\n",
    "# 虽然 jieba 有新词识别能力，但是自行添加新词可以保证更高的正确率。\n",
    "\n",
    "# 用法： jieba.load_userdict(file_name) \n",
    "#          参数：file_name 为文件类对象或自定义词典的路径\n",
    "# 词典格式和 dict.txt 一样，一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。\n",
    "# file_name 若为路径或二进制方式打开的文件，则文件必须为 UTF-8 编码。\n",
    "# 词频省略时使用自动计算的能保证分出该词的词频。\n",
    "\n",
    "# 例如：\n",
    "#     创新办 3 i\n",
    "#     云计算 5\n",
    "#     凱特琳 nz\n",
    "#     台中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 更改分词器（默认为 jieba.dt）的 tmp_dir 和 cache_file 属性，\n",
    "# 可分别指定缓存文件所在的文件夹及其文件名，用于受限的文件系统。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 自定义词典的userdict.txt示例\n",
    "# 云计算5\n",
    "# 李小福2 nr\n",
    "# 创新办3 i\n",
    "# easy_install 3 eng\n",
    "# 好用300\n",
    "# 韩玉赏鉴3 nz\n",
    "# 八一双鹿3 nz\n",
    "# 台中\n",
    "# 凯特琳nz\n",
    "# Edu Trust认证2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 调整词典\n",
    "# 使用 add_word(word, freq=None, tag=None) \n",
    "#  和 del_word(word) 可在程序中动态修改词典。\n",
    "\n",
    "# 使用 suggest_freq(segment, tune=True) \n",
    "# 可调节单个词语的词频，使其能（或不能）被分出来。\n",
    "# 注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果/放到/post/中/将/出错/。\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果/放到/post/中/将/出错/。\n"
     ]
    }
   ],
   "source": [
    "jieba.suggest_freq(('中','将'), True)\n",
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果/放到/post/中将/出错/。\n"
     ]
    }
   ],
   "source": [
    "jieba.suggest_freq(('中将'), True)\n",
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq(('中','将'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq(('中将'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「/台中/」/正确/应该/不会/被/切开\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq('台中', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「/台中/」/正确/应该/不会/被/切开\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 通过用户自定义词典来增强歧义纠错能力。\n",
    "# https://github.com/fxsjy/jieba/issues/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.关键词抽取\n",
    "# 基于TF-IDF算法的关键词抽取\n",
    "# 基于TextRank算法的关键词抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基于TF-IDF算法的关键词抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jieba.analyse.extract_tags(sentence, topK = 20, \n",
    "#                            withWeight=False,allowPOS=())\n",
    "# 参数：sentence 为待提取的文本\n",
    "#      topK 为返回几个TF/IDF权重最大的关键词，默认值为20\n",
    "#      withWeight 为是否一并返回关键词权重值，默认值为False\n",
    "#      allowPOS 仅包括指定词性的词，默认值为空，即不筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jieba.analyse.TFIDF(idf_path = None)\n",
    "# 新建TFIDF实例，idf_path为IDF频率文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基于TextRank算法的关键词抽取\n",
    "# jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v')) 直接使用，接口相同，注意默认过滤词性。\n",
    "# jieba.analyse.TextRank() 新建自定义 TextRank 实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基本思想:\n",
    "# 将待抽取关键词的文本进行分词\n",
    "# 以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图\n",
    "# 计算图中节点的PageRank，注意是无向带权图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jieba.posseg.POSTokenizer(tokenizer=None)\n",
    "# 新建自定义分词器，tokenizer参数可指定内部使用的jieba.Tokenizer分词器。\n",
    "# jieba.posseg.dt 为默认词性标注分词器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 标注句子分词后每个词的词性，采用和ictclas兼容的标记法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba.posseg as pseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "爱 v\n",
      "北京 ns\n",
      "天安门 ns\n"
     ]
    }
   ],
   "source": [
    "words = pseg.cut('我爱北京天安门')\n",
    "for word,flag in words:\n",
    "    print('%s %s'%(word, flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.并行分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 原理：将目标文本按行分隔后，把各行文本分配到多个Python进程并行分词，\n",
    "# 然后归并结果，从而获得分词速度的可观提升。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基于python自带的multiprocessing模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 用法：\n",
    "# jieba.enable_parallel(4)  # 开启并行分词模式，参数为并行进程数\n",
    "# jieba.disable_parallel()  # 关闭并行分词模式\n",
    "# 注意： 并行分词仅支持默认分词器jieba.dt 和 jieba.posseg.dt。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.Tokenize:返回词语在原文的起止位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 永和\t\t start:0 \t\t end:2\n",
      "word 服装\t\t start:2 \t\t end:4\n",
      "word 饰品\t\t start:4 \t\t end:6\n",
      "word 有限公司\t\t start:6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "# 默认模式\n",
    "result = jieba.tokenize('永和服装饰品有限公司')\n",
    "for tk in result:\n",
    "    print('word %s\\t\\t start:%d \\t\\t end:%d'%(tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 永和 \t\t start:0 \t\t end:2\n",
      "word 服装 \t\t start:2 \t\t end:4\n",
      "word 饰品 \t\t start:4 \t\t end:6\n",
      "word 有限 \t\t start:6 \t\t end:8\n",
      "word 公司 \t\t start:8 \t\t end:10\n",
      "word 有限公司 \t\t start:6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "# 搜索模式\n",
    "result = jieba.tokenize('永和服装饰品有限公司',mode = 'search')\n",
    "for tk in result:\n",
    "    print('word %s \\t\\t start:%d \\t\\t end:%d'%(tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7.ChineseAnalyzer for Whoosh 搜索引擎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jieba.analyse import ChineseAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新办/主任/也/是/云计算/方面/的/专家/;/ /什么/是/八一双鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉赏鉴/”/的/标题/，/在/自定义/词库/中/也/增加/了/此/词为/N/类/\n",
      "/「/台中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨烯/」/；/此時/又/可以/分出/來/凱特琳/了/。\n"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict('userdict.txt')\n",
    "jieba.add_word('石墨烯')\n",
    "jieba.add_word('凱特琳')\n",
    "jieba.del_word('自定义词')\n",
    "\n",
    "test_sent = (\"李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿\\n\"\n",
    "             \"例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类\\n\"\n",
    "             \"「台中」正確應該不會被切開。mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\")\n",
    "\n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print('='*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.posseg as pseg  #分词+词性标注\n",
    "result = pseg.cut(test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福 / nr ,\n",
      "是 / v ,\n",
      "创新办 / i ,\n",
      "主任 / b ,\n",
      "也 / d ,\n",
      "是 / v ,\n",
      "云计算 / x ,\n",
      "方面 / n ,\n",
      "的 / uj ,\n",
      "专家 / n ,\n",
      "; / x ,\n",
      "  / x ,\n",
      "什么 / r ,\n",
      "是 / v ,\n",
      "八一双鹿 / nz ,\n",
      "\n",
      " / x ,\n",
      "例如 / v ,\n",
      "我 / r ,\n",
      "输入 / v ,\n",
      "一个 / m ,\n",
      "带 / v ,\n",
      "“ / x ,\n",
      "韩玉赏鉴 / nz ,\n",
      "” / x ,\n",
      "的 / uj ,\n",
      "标题 / n ,\n",
      "， / x ,\n",
      "在 / p ,\n",
      "自定义 / l ,\n",
      "词库 / n ,\n",
      "中 / f ,\n",
      "也 / d ,\n",
      "增加 / v ,\n",
      "了 / ul ,\n",
      "此 / r ,\n",
      "词 / n ,\n",
      "为 / p ,\n",
      "N / eng ,\n",
      "类 / q ,\n",
      "\n",
      " / x ,\n",
      "「 / x ,\n",
      "台中 / s ,\n",
      "」 / x ,\n",
      "正確 / ad ,\n",
      "應該 / v ,\n",
      "不 / d ,\n",
      "會 / v ,\n",
      "被 / p ,\n",
      "切開 / ad ,\n",
      "。 / x ,\n",
      "mac / eng ,\n",
      "上 / f ,\n",
      "可 / v ,\n",
      "分出 / v ,\n",
      "「 / x ,\n",
      "石墨烯 / x ,\n",
      "」 / x ,\n",
      "； / x ,\n",
      "此時 / c ,\n",
      "又 / d ,\n",
      "可以 / c ,\n",
      "分出 / v ,\n",
      "來 / zg ,\n",
      "凱特琳 / x ,\n",
      "了 / ul ,\n",
      "。 / x ,\n"
     ]
    }
   ],
   "source": [
    "for w in result:\n",
    "    print(w.word,'/',w.flag,',',end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pair('李小福', 'nr'),\n",
       " pair('是', 'v'),\n",
       " pair('创新办', 'i'),\n",
       " pair('主任', 'b'),\n",
       " pair('也', 'd'),\n",
       " pair('是', 'v'),\n",
       " pair('云计算', 'x'),\n",
       " pair('方面', 'n'),\n",
       " pair('的', 'uj'),\n",
       " pair('专家', 'n'),\n",
       " pair(';', 'x'),\n",
       " pair(' ', 'x'),\n",
       " pair('什么', 'r'),\n",
       " pair('是', 'v'),\n",
       " pair('八一双鹿', 'nz'),\n",
       " pair('\\n', 'x'),\n",
       " pair('例如', 'v'),\n",
       " pair('我', 'r'),\n",
       " pair('输入', 'v'),\n",
       " pair('一个', 'm'),\n",
       " pair('带', 'v'),\n",
       " pair('“', 'x'),\n",
       " pair('韩玉赏鉴', 'nz'),\n",
       " pair('”', 'x'),\n",
       " pair('的', 'uj'),\n",
       " pair('标题', 'n'),\n",
       " pair('，', 'x'),\n",
       " pair('在', 'p'),\n",
       " pair('自定义', 'l'),\n",
       " pair('词库', 'n'),\n",
       " pair('中', 'f'),\n",
       " pair('也', 'd'),\n",
       " pair('增加', 'v'),\n",
       " pair('了', 'ul'),\n",
       " pair('此', 'r'),\n",
       " pair('词', 'n'),\n",
       " pair('为', 'p'),\n",
       " pair('N', 'eng'),\n",
       " pair('类', 'q'),\n",
       " pair('\\n', 'x'),\n",
       " pair('「', 'x'),\n",
       " pair('台中', 's'),\n",
       " pair('」', 'x'),\n",
       " pair('正確', 'ad'),\n",
       " pair('應該', 'v'),\n",
       " pair('不', 'd'),\n",
       " pair('會', 'v'),\n",
       " pair('被', 'p'),\n",
       " pair('切開', 'ad'),\n",
       " pair('。', 'x'),\n",
       " pair('mac', 'eng'),\n",
       " pair('上', 'f'),\n",
       " pair('可', 'v'),\n",
       " pair('分出', 'v'),\n",
       " pair('「', 'x'),\n",
       " pair('石墨烯', 'x'),\n",
       " pair('」', 'x'),\n",
       " pair('；', 'x'),\n",
       " pair('此時', 'c'),\n",
       " pair('又', 'd'),\n",
       " pair('可以', 'c'),\n",
       " pair('分出', 'v'),\n",
       " pair('來', 'zg'),\n",
       " pair('凱特琳', 'x'),\n",
       " pair('了', 'ul'),\n",
       " pair('。', 'x')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba.posseg as pseg  #分词+词性标注\n",
    "result = pseg.cut(test_sent)\n",
    "list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['easy_install', ' ', 'is', ' ', 'great']\n"
     ]
    }
   ],
   "source": [
    "terms = jieba.cut('easy_install is great')\n",
    "print(list(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', '的', '正则表达式', '是', '好', '用', '的']\n"
     ]
    }
   ],
   "source": [
    "terms = jieba.cut('python的正则表达式是好用的')\n",
    "print(list(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test frequency tune\n",
    "testlist = [\n",
    "('今天天气不错', ('今天', '天气')),\n",
    "('如果放到post中将出错。', ('中', '将')),\n",
    "('我们中出了一个叛徒', ('中', '出')),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天/天气/不错\n",
      ">>>> 今天天气\n",
      "今天天气 Before: 0, After: 0\n",
      "今天/天气/不错\n",
      "----------------------------------------\n",
      "如果/放到/post/中/将/出错/。\n",
      ">>>> 中将\n",
      "中将 Before: 494, After: 494\n",
      "如果/放到/post/中/将/出错/。\n",
      "----------------------------------------\n",
      "我们/中/出/了/一个/叛徒\n",
      ">>>> 中出\n",
      "中出 Before: 3, After: 3\n",
      "我们/中/出/了/一个/叛徒\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sent, seg in testlist:\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    word = ''.join(seg)\n",
    "    print('>>>>',word)\n",
    "    print('%s Before: %s, After: %s' % (word, jieba.get_FREQ(word), jieba.suggest_freq(seg, True)))\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
