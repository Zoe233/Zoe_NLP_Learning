第6章 学习分类文本
6.1 有监督分类
    性别鉴定
    选择正确的特征
    文档分类
    探索上下文语境
    序列分类
    其他序列分类方法
6.2 有监督分类的更多例子
    句子分割
    识别对话行为类型
    识别文字蕴含
    拓展到大型数据集
6.3 评估
    测试集
    准确度
    精确度和召回率
    混淆矩阵
    交叉验证
6.4 决策树
    熵和信息增益
6.5 朴素贝叶斯分类器
    潜在概率模型
    零计数和平滑
    非二元特征
    独立的朴素
    双重计数的原因
6.6 最大熵分类器
    最大熵模型
    熵的最大化
    生成式分类器对比条件式分类器
6.7 为语言模式建模
    模型告诉我们什么？


    模式识别是自然语言处理的一个核心部分。

    以-ed结尾的词往往是过去时态动词；
    频繁使用will时新闻文本的暗示...

    这些可观察到的模式 -- 词的结构和词频 -- 恰好与特定方面的含义关联，如：时态和主题。

    本章的目标是要回答下列问题：
        1. 我们怎样才能识别语言数据中能明显用于对其分类的特征？
        2. 我们怎样才能构建语言模型，用于自动执行语言处理任务？
        3. 从这些模型中我们可以学到哪些关于语言的知识？
    一路上，我们将研究一些重要的机器学习技术，包括决策树、朴素贝叶斯分类器和最大熵分类。

6.1 有监督分类

    分类是为给定的输入选择正确的类标签的任务。
    在基本的分类任务中，每个输入被认为是与所有其他输入隔离的， 并且标签集是预先定义的。

    例子：
        垃圾邮件判定；
        新闻主题分类；
        决定词bank给定的出现是用来指河的坡岸、一个金融机构、向一边倾斜的动作还是在金融机构里的存储行为。

    基本的分类任务有很多有序的变种。
    例如：在多类分类中，每个实例可以分配多个标签；
         在开放性分类中，标签集事先没有定义的；
         在序列分类中，一个输入链表作为一个整体分类。

    如果分类的建立基于包含每个输入的正确标签的训练语料，被称为 有监督分类。
    有监督分类使用的框架图。
6.1.1 性别鉴定
    似然比，可以用于比较不同特征-结果关系。

    在处理大型语料时，构建一个包含每一个实例的特征的单独的链表会使用大量的内存。
    在这种情况下，使用函数nltk.classify.apply_features，返回一个对象。
        >>> def gender_features(word):
        ...     return {'last_letter':word[-1]}

        >>> from nltk.classify import apply_features
        >>> train_set = apply_features(gender_features, names[500:])
        >>> test_set = apply_features(gender_features, names[:500])

6.1.2 选择正确的特征
    选择相关的特征，并决定如何为一个学习方法编码它们，这对学习方法提取一个好的模型可以产生巨大的影响。
    建立一个分类器的很多有趣的工作之一是找出哪些特征可能是相关的，以及我们如何能够表示它们。
    虽然使用相当简单而明显的特征集往往可以得到像样的性能，但是使用精心构建的基于对当前任务的透彻理解的特征，通常会显著提高收益。

    典型地，特征提取通过反复试验和错误的过程建立的，由哪些信息是与问题相关的直觉指引的。
    它通常以"厨房水槽"的方法开始，包括你能想到的所有特征，然后检查哪些特征是实际有用的。

    太多特征-- 一般化性能差，高度依赖训练数据特征--过拟合。

    一旦初始特征集被选定，完善特征集的一个非常有成效的方法是 错误分析。
    选择一个开发集，包含用于创建模型的语料数据，将开发集分为 训练集 和 测试集。
    使用测试集，检查个别错误案例，分析，尝试确定什么额外信息能使其能够做出正确的决定，调整特征集。
    迭代验证这个过程。

6.1.3 文档分类
    文档特征生成器
6.1.4 探索上下文语境
    在特征生成器中增加上下文的语境的特征。
    在一般情况下，简单的分类器总是将每一个输入与所有其他输入独立对待。
    然而，如词性标注，我们感兴趣的是解决彼此密切相关的分类问题。

6.1.5 序列分类
    为了捕捉相关的分类任务之间的依赖关系，我们可以使用 联合分类器模型，收集有关输入，选择适当的标签。
    在词性标注的例子中，各种不同的 序列分类器 模型可以被用来为一个给定的句子中的所有的词共同选择词性标签。

    一种序列分类器策略，称为 连续分类 或 贪婪序列分类，是为第一个输入找到最有可能的类标签，然后使用这个问题的答案帮助找到下一个输入的最佳的标签。
    这个过程可以不断重复直到所有的输入都被贴上标签。
    bigram标注器 采用的方法就是这种--它一开始为句子的第一个词选择词性标记，然后为每个随后的词选择标记，基于词本身和前面词的预测的标记。

    使用连续分类器进行词性标注 -- example见'lec06_seq_POS_tagginng'


    缺点：
        一旦我们的决定作出，则无法更改。
        这个问题的解决方案是采取转型策略。

6.1.6 其他序列分类方法

    转型联合分类的工作原理是为输入的标签创建一个初始值，然后反复提炼那个值，尝试修复相关输入之间的不一致。
    Brill标注器，是这种策略的一个很好的例子。

    另一种方案是为词性标记所有可能的序列打分，选择总得分最高的序列。
    隐马尔科夫模型就采取这种方法。

    隐马尔科夫模型类似于连续分类器，它不光看输入也看已预测标记的历史。
    然而，不是简单地找出一个给定的词的单个最好的标签，而是为标记产生一个概率分布。
    然后将这些概率结合起来计算标记序列的概率得分，最高概率的标记序列会被选中。
    不幸的是，可能的标签序列的数量相当大。
    为了避免单独考虑所有可能的序列，隐马尔科夫模型要求特征提取器只看最近的标记（或最近的n个标记，其中n是相当小的）。
    由于这种限制，它可以使用动态规划，有效地找出最优可能的标记序列。
    特别是，对每个连续的词索引i，每个可能的当前及以前的标记都被计算得分。
    这种同样基础的方法被两个更先进的模型所采用，它们被称为 最大熵马尔科夫模型 和 线性链条件随机场 模型；
    但为标记序列打分用的是不同的算法。



6.2 有监督分类的更多例子
    句子分割
    识别对话行为类型
    识别文字蕴含
    拓展到大型数据集
6.3 评估
    测试集
    准确度
    精确度和召回率
    混淆矩阵
    交叉验证