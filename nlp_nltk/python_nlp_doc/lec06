第6章 学习分类文本
6.1 有监督分类
    性别鉴定
    选择正确的特征
    文档分类
    探索上下文语境
    序列分类
    其他序列分类方法
6.2 有监督分类的更多例子
    句子分割
    识别对话行为类型
    识别文字蕴含
    拓展到大型数据集
6.3 评估
    测试集
    准确度
    精确度和召回率
    混淆矩阵
    交叉验证
6.4 决策树
    熵和信息增益
6.5 朴素贝叶斯分类器
    潜在概率模型
    零计数和平滑
    非二元特征
    独立的朴素
    双重计数的原因
6.6 最大熵分类器
    最大熵模型
    熵的最大化
    生成式分类器对比条件式分类器
6.7 为语言模式建模
    模型告诉我们什么？


    模式识别是自然语言处理的一个核心部分。

    以-ed结尾的词往往是过去时态动词；
    频繁使用will时新闻文本的暗示...

    这些可观察到的模式 -- 词的结构和词频 -- 恰好与特定方面的含义关联，如：时态和主题。

    本章的目标是要回答下列问题：
        1. 我们怎样才能识别语言数据中能明显用于对其分类的特征？
        2. 我们怎样才能构建语言模型，用于自动执行语言处理任务？
        3. 从这些模型中我们可以学到哪些关于语言的知识？
    一路上，我们将研究一些重要的机器学习技术，包括决策树、朴素贝叶斯分类器和最大熵分类。

6.1 有监督分类

    分类是为给定的输入选择正确的类标签的任务。
    在基本的分类任务中，每个输入被认为是与所有其他输入隔离的， 并且标签集是预先定义的。

    例子：
        垃圾邮件判定；
        新闻主题分类；
        决定词bank给定的出现是用来指河的坡岸、一个金融机构、向一边倾斜的动作还是在金融机构里的存储行为。

    基本的分类任务有很多有序的变种。
    例如：在多类分类中，每个实例可以分配多个标签；
         在开放性分类中，标签集事先没有定义的；
         在序列分类中，一个输入链表作为一个整体分类。

    如果分类的建立基于包含每个输入的正确标签的训练语料，被称为 有监督分类。
    有监督分类使用的框架图。
6.1.1 性别鉴定
    似然比，可以用于比较不同特征-结果关系。

    在处理大型语料时，构建一个包含每一个实例的特征的单独的链表会使用大量的内存。
    在这种情况下，使用函数nltk.classify.apply_features，返回一个对象。
        >>> def gender_features(word):
        ...     return {'last_letter':word[-1]}

        >>> from nltk.classify import apply_features
        >>> train_set = apply_features(gender_features, names[500:])
        >>> test_set = apply_features(gender_features, names[:500])

6.1.2 选择正确的特征
    选择相关的特征，并决定如何为一个学习方法编码它们，这对学习方法提取一个好的模型可以产生巨大的影响。
    建立一个分类器的很多有趣的工作之一是找出哪些特征可能是相关的，以及我们如何能够表示它们。
    虽然使用相当简单而明显的特征集往往可以得到像样的性能，但是使用精心构建的基于对当前任务的透彻理解的特征，通常会显著提高收益。

    典型地，特征提取通过反复试验和错误的过程建立的，由哪些信息是与问题相关的直觉指引的。
    它通常以"厨房水槽"的方法开始，包括你能想到的所有特征，然后检查哪些特征是实际有用的。

    太多特征-- 一般化性能差，高度依赖训练数据特征--过拟合。

    一旦初始特征集被选定，完善特征集的一个非常有成效的方法是 错误分析。
    选择一个开发集，包含用于创建模型的语料数据，将开发集分为 训练集 和 测试集。
    使用测试集，检查个别错误案例，分析，尝试确定什么额外信息能使其能够做出正确的决定，调整特征集。
    迭代验证这个过程。

6.1.3 文档分类
    文档特征生成器
6.1.4 探索上下文语境
    在特征生成器中增加上下文的语境的特征。
    在一般情况下，简单的分类器总是将每一个输入与所有其他输入独立对待。
    然而，如词性标注，我们感兴趣的是解决彼此密切相关的分类问题。

6.1.5 序列分类
    为了捕捉相关的分类任务之间的依赖关系，我们可以使用 联合分类器模型，收集有关输入，选择适当的标签。
    在词性标注的例子中，各种不同的 序列分类器 模型可以被用来为一个给定的句子中的所有的词共同选择词性标签。

    一种序列分类器策略，称为 连续分类 或 贪婪序列分类，是为第一个输入找到最有可能的类标签，然后使用这个问题的答案帮助找到下一个输入的最佳的标签。
    这个过程可以不断重复直到所有的输入都被贴上标签。
    bigram标注器 采用的方法就是这种--它一开始为句子的第一个词选择词性标记，然后为每个随后的词选择标记，基于词本身和前面词的预测的标记。

    使用连续分类器进行词性标注 -- example见'lec06_seq_POS_tagginng'


    缺点：
        一旦我们的决定作出，则无法更改。
        这个问题的解决方案是采取转型策略。

6.1.6 其他序列分类方法

    转型联合分类的工作原理是为输入的标签创建一个初始值，然后反复提炼那个值，尝试修复相关输入之间的不一致。
    Brill标注器，是这种策略的一个很好的例子。

    另一种方案是为词性标记所有可能的序列打分，选择总得分最高的序列。
    隐马尔科夫模型就采取这种方法。

    隐马尔科夫模型类似于连续分类器，它不光看输入也看已预测标记的历史。
    然而，不是简单地找出一个给定的词的单个最好的标签，而是为标记产生一个概率分布。
    然后将这些概率结合起来计算标记序列的概率得分，最高概率的标记序列会被选中。
    不幸的是，可能的标签序列的数量相当大。
    为了避免单独考虑所有可能的序列，隐马尔科夫模型要求特征提取器只看最近的标记（或最近的n个标记，其中n是相当小的）。
    由于这种限制，它可以使用动态规划，有效地找出最优可能的标记序列。
    特别是，对每个连续的词索引i，每个可能的当前及以前的标记都被计算得分。
    这种同样基础的方法被两个更先进的模型所采用，它们被称为 最大熵马尔科夫模型 和 线性链条件随机场 模型；
    但为标记序列打分用的是不同的算法。



6.2 有监督分类的更多例子
    例子：lec06_02_classifiers
6.2.1 句子分割
    句子分割可以看作是一个标点符号的分类任务：每当我们遇到一个可能会结束的一个句子的符号，如句号或问号，我们必须决定它是否终止了当前句子。

6.2.2 识别对话行为类型
6.2.3 识别文字蕴含
6.2.4 拓展到大型数据集


6.3 评估

    为了决定一个分类模型是否准确地捕捉了模式，我们必须评估该模型。
    评估的结果对于决定模型是多么值得信赖以及我们如何使用它是非常重要的。
    评估也可以使一个有效的工具，用于指导我们在未来改进模型。

6.3.1 测试集

    大多数评估技术为模型计算一个得分，通过比较它在测试集（或评估及）中为输入生成的标签与那些输入的正确标签。

    建立测试集时，往往是一个可用于测试的和可用于训练的数据量之间的权衡。
    选择测试集时另一个需要考虑的是测试集中实例与开发集中的实例的相似程度。

6.3.2 准确度

    用于评估一个分类最简单的度量是准确度，测量测试集上分类器正确标注的输入的比例。

    nltk.classify.accuracy()函数会在给定的测试集上计算分类器模型的准确度。

6.3.3 精确度和召回率
    另一个准确度分数可能会产生误导的实例时在"搜索"任务中，如：信息检索，我们试图找出与特定任务有关的文档。

    由于不相关的文档的数量远远多于相关文档的数量，一个将每一个文档都标记为无关的模型的准确度分数将非常接近100%。

    因此，对搜索任务使用不同的测试集是很常见的。
        真阳性 -- 是相关项目中我们正确识别为相关的。
        真阴性 -- 是不相关项目中我们正确识别为不相关的。
        假阳性（或 I型错误） -- 是不相关项目中我们错误识别为相关的。
        假阴性（或 II型错误） -- 是相关项目中我们错误识别为不相关的。

                            Actual Class
                                 1                          0
        Predicted Class   1     True Positive(TP)     False Positive(FP) == Precision = tp/(tp+fp)
                          0     False Negative(FN)    True Negative(TN)
                                    ||
                                Recall = TP/(TP+FN)                      ==> Accuracy = (TP+TN)/(TP+FN+FP+TN)
    四个指标：
        准确率（Accuracy） A = (TP + TN)/(P+N) = (TP + TN)/(TP + FN + FP + TN);
            反映了分类器统对整个样本的判定能力——能将正的判定为正，负的判定为负

        精确度（Precision) -- 表示我们发现的项目中有多少的相关的，TP/(TP+FP)
            精确度 = predict结果为正确中事实也是正确的个数 / predict的结果为正确的个数
            反映了被分类器判定的正例中真正的正例样本的比重。

        召回率 (Recall) -- 表示相关的项目中我们发现了多少，TP/(TP+FN)
            召回率 = 测试集中实际是正确的个数且预测也是正确的个数 / 测试集中实际是正确的个数
            反映了被正确判定的正例占总的正例的比重

        F-度量值（F-Measure,F-得分,F-Score) -- 组合精确度和召回率为一个单独的得分，
                        被定义为精确度和召回率的调和平均数。
                           (2*Precision*Recall)/(Precision+Recall)
    一般来说，准确率和召回率反映了分类器性能的两个方面，单一依靠某个指标并不能较为全面地评价一个分类器的性能。
    引入F1-Score作为综合指标，就是为了平衡准确率和召回率的影响，较为全面地评价一个分类器。
    有时候考虑到不同的需求，可能会更看重准确率或者召回率。这时我们可以引入F2-Score和F0.5-Score。
    包括F1-Score，这三个指标都来自以下定义，只是参数不同。

        其中，F1-Score是指准确率和召回率一样重要；
        F2-Score是指召回率比准确率重要一倍；
        F0.5-Score是指准确率比召回率重要一倍。

6.3.4 混淆矩阵

    当处理有3个或更多的标签的分类任务时，基于模型错误类型细分模型的错误是有信息量的。
    一个 混淆矩阵 是一个表，其中每个cells[i,j]表示正确的标签i被预测为标签j的次数。
    因此，对角线项cells[i,i]表示正确预测的标签，非对角线项目表示错误。

>>> import nltk
>>> def tag_list(tagged_sents):
...     return [tag for sent in tagged_sents for (word,tag) in sent]
...
>>> def apply_tagger(tagger, corpus):
...     return [tagger.tag(nltk.tag.untag(sent)) for sent in corpus]
...

>>> sents = brown.tagged_sents(categories='editorial')
>>> t0 = nltk.DefaultTagger('NN')
>>> t1 = nltk.UnigramTagger(sents, backoff=t0)
>>> t2 = nltk.BigramTagger(sents, backoff=t1)
>>> gold = tag_list(nltk.corpus.brown.tagged_sents(categories='editorial'))
>>> cm = nltk.ConfusionMatrix(gold, test)

6.3.5 交叉验证

    为了评估我们的模型，我们必须为测试集保留一部分已标注的数据。

    在不同的测试集上执行多个评估，然后组合这些评估的得分，这种技术被称为交叉验证。
    特别是，我们将原始语料细分为N个子集称为折叠（folds).

    对于每一个这些的折叠，我们使用除这个折叠中的数据外其他所有数据训练模型，然后在这个折叠上测试模型。
    即使个别的折叠可能是太小了而不能在其上给出准确的评价分数，综合评估得分是基于大量的数据，因此是相当可靠的。

    第二，同样重要的，采用交叉验证的优势是，它可以让我们研究不同的训练集上性能变化有多大。
    如果我们从所有N 个训练集得到非常相似的分数，然后我们可以相当有信心，得分是准确的。
    另一方面，如果N 个训练集上分数很大不同，那么，我们应该对评估得分的准确性持怀疑态度。

    什么是交叉验证法？
        它的基本思想就是将原始数据（dataset）进行分组，一部分做为训练集来训练模型，另一部分做为测试集来评价模型。

    为什么用交叉验证法？
        交叉验证用于评估模型的预测性能，尤其是训练好的模型在新数据上的表现，可以在一定程度上减小过拟合。
        还可以从有限的数据中获取尽可能多的有效信息

    主要有哪些方法？
        1. 留出法 （holdout cross validation）
            训练集、验证集和测试集。
            训练集用于训练模型，验证集用于模型的参数选择配置，测试集对于模型来说是未知数据，用于评估模型的泛化能力。

        2. k 折交叉验证（k-fold cross validation）加以改进：
            k 折交叉验证通过对 k 个不同分组训练的结果进行平均来减少方差，因此模型的性能对数据的划分就不那么敏感。

        3. 留一法（Leave one out cross validation），每次的测试集都只有一个样本，要进行 m 次训练和预测。


6.4 决策树
    自动生成分类模型的三种机器学习方法：决策树、朴素贝叶斯分类器和最大熵分类器。

    可以把这些学习方法看做黑盒子，直接训练模式，使用它们进行预测而不需要理解它们是如何工作的。
    仔细了解这些学习方法是如何基于一个训练集上的数据选择模型。
    了解这些方法可以帮助指导我们选择相应的特征，尤其是我们关于那些特征如何编码的决定。
    理解生成的模型可以让我们更好的提取信息，哪些特征对有信息量，哪些特征之间如何相互关联。


    决策树 是一个简单的为输入值选择标签的流程图。
    这个流程图由检查特征值的 决策节点 和 分配标签的 叶节点 组成。
    为输入值选择标签，我们以流程图的初始决策节点（称为其 根节点）开始。
    此节点包含一个条件，检查输入值的特征之一，基于该特征的值选择一个分支。
    沿着这个描述我们输入值的分支，我们到达了一个新的决策节点，有一个关于输入值的特征的新的条件。
    我们继续沿着每个节点的条件选择的分支，直到到达叶节点，它为输入值提供了一个标签。

6.4.1 熵和信息增益

6.5 朴素贝叶斯分类器
    潜在概率模型
    零计数和平滑
    非二元特征
    独立的朴素
    双重计数的原因
6.6 最大熵分类器
    最大熵模型
    熵的最大化
    生成式分类器对比条件式分类器
6.7 为语言模式建模
    模型告诉我们什么？
6.8 小结

    为语料库中的语言数据建模可以帮助我们理解语言模型，也可以用于预测新语言数据。

    有监督分类器使用加标签的训练语料库来建立模型，基于输入的特征，预测那个输入的标签。

    有监督分类器可以执行多种NLP任务，包括文档分类、词性标注、语句分隔、对话行为类型识别以及确定蕴涵关系和很多其他任务。

    训练一个有监督分类器时，你应该把语料分为三个数据集：
    用于构造分类器模型的训练集，用于帮助选择和调整模型特性的开发测试集，以及用于评估最终模型性能的测试集。

    评估一个有监督分类器时，重要的是你要使用新鲜的没有包含在训练集或开发测试集中的数据。否则，你的评估结果可能会不切实际地乐观。

    决策树可以自动地构建树结构的流程图，用于为输入变量值基于它们的特征加标签，虽然它们易于解释，但不适合处理特性值在决定合适标签过程中相互影响的情况。

    在朴素贝叶斯分类器中，每个特征决定应该使用哪个标签的贡献是独立的。
    它允许特征值间有关联，但当两个或更多的特征高度相关时将会有问题。

    最大熵分类器使用的基本模型与朴素贝叶斯相似；不过，它们使用了迭代优化来寻找使训练集的概率最大化的特征权值集合。

    大多数从语料库自动构建的模型都是描述性的，也就是说，它们让我们知道哪些特征与给定的模式或结构相关，
    但它们没有给出关于这些特征和模式之间的因果关系的任何信息。
